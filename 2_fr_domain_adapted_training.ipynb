{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP05iepSqjtNZwNwpmjATn+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cw118/domain-adapted-nmt/blob/main/2_fr_domain_adapted_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Domain-adapted NMT\n",
        "\n",
        "## Training NMT models"
      ],
      "metadata": {
        "id": "K6TDCS_KZ3UD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eRyWkpHU3-w",
        "outputId": "1ed9df35-7ec4-4827-929b-bc1a7b483c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenNMT-py\n",
            "  Downloading OpenNMT_py-3.4.3-py3-none-any.whl (257 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/257.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/257.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.3/257.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<2.2,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.1.0+cu121)\n",
            "Collecting configargparse (from OpenNMT-py)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting ctranslate2<4,>=3.17 (from OpenNMT-py)\n",
            "  Downloading ctranslate2-3.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.15.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.2.5)\n",
            "Collecting waitress (from OpenNMT-py)\n",
            "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyonmttok<2,>=1.35 (from OpenNMT-py)\n",
            "  Downloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (6.0.1)\n",
            "Collecting sacrebleu (from OpenNMT-py)\n",
            "  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from OpenNMT-py)\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from OpenNMT-py)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasttext-wheel (from OpenNMT-py)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (1.23.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.5.2)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2.1.0)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel->OpenNMT-py)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (8.1.7)\n",
            "Collecting portalocker (from sacrebleu->OpenNMT-py)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->OpenNMT-py)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (4.9.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (4.66.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.10.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.2,>=2.0.1->OpenNMT-py) (2.1.3)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.10.0->spacy->OpenNMT-py) (0.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.2,>=2.0.1->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.3->OpenNMT-py) (3.2.2)\n",
            "Installing collected packages: waitress, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, ctranslate2, configargparse, colorama, sacrebleu, fasttext-wheel, OpenNMT-py\n",
            "Successfully installed OpenNMT-py-3.4.3 colorama-0.4.6 configargparse-1.7 ctranslate2-3.24.0 fasttext-wheel-0.9.2 portalocker-2.8.2 pyahocorasick-2.0.0 pybind11-2.11.1 pyonmttok-1.37.1 rapidfuzz-3.6.1 sacrebleu-2.4.0 waitress-2.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install OpenNMT-py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change into folder where prepared datasets were saved in the text processing step\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex2ZuFaQZ2bc",
        "outputId": "fdbb4f87-8f81-411c-ca66-98efaf416141"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/domain-adapted-nmt/nmt-tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQVFhh1Fp7mt",
        "outputId": "937cadaa-4e16-419d-a5b1-11d25ae38d80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/domain-adapted-nmt/nmt-tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the general/base model"
      ],
      "metadata": {
        "id": "Hql2_poQx3ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# corpora generated from step 1: https://drive.google.com/drive/folders/1fVe2e2MvT2CCTpSSDrBkykoR-7JKy-w4?usp=sharing\n",
        "config = '''# config.yaml\n",
        "\n",
        "\n",
        "## where the samples will be written\n",
        "save_data: run\n",
        "\n",
        "# train the general/base model first\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: corpora/enfr/en-fr-general.en-filtered.en.subword.train\n",
        "        path_tgt: corpora/enfr/en-fr-general.fr-filtered.fr.subword.train\n",
        "        transforms: [filtertoolong]\n",
        "        weight: 1\n",
        "    valid:\n",
        "        path_src: corpora/enfr/en-fr-general.en-filtered.en.subword.dev\n",
        "        path_tgt: corpora/enfr/en-fr-general.fr-filtered.fr.subword.dev\n",
        "        transforms: [filtertoolong]\n",
        "\n",
        "# vocab files generated by onmt_build_vocab\n",
        "src_vocab: run/source.vocab\n",
        "tgt_vocab: run/target.vocab\n",
        "\n",
        "# vocabulary size: should be same as in sentencepiece\n",
        "src_vocab_size: 50000\n",
        "tgt_vocab_size: 50000\n",
        "\n",
        "# Filter out source/target longer than n if [filtertoolong] enabled\n",
        "src_seq_length: 150\n",
        "src_seq_length: 150\n",
        "\n",
        "# Tokenization options\n",
        "src_subword_model: source-general.model\n",
        "tgt_subword_model: target-general.model\n",
        "\n",
        "# Where to save the log file and the output models/checkpoints\n",
        "log_file: train.log\n",
        "save_model: models/model-base.enfr\n",
        "\n",
        "# Stop training if it does not improve after n validations\n",
        "early_stopping: 4\n",
        "\n",
        "# Default: 5000 - Save a model checkpoint for each n\n",
        "save_checkpoint_steps: 2000\n",
        "\n",
        "# To save space, limit checkpoints to last n\n",
        "# keep_checkpoint: 4\n",
        "\n",
        "seed: 3435\n",
        "\n",
        "# For fine-tuning, add up the required steps to the original steps\n",
        "train_steps: 10000\n",
        "\n",
        "# Default: 10000 - Run validation after n steps\n",
        "valid_steps: 2000\n",
        "\n",
        "# Default: 4000 - for large datasets, try up to 8000\n",
        "warmup_steps: 2000\n",
        "report_every: 200\n",
        "\n",
        "# Number of GPUs, and IDs of GPUs\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Batching\n",
        "bucket_size: 262144\n",
        "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
        "valid_batch_size: 2048\n",
        "max_generator_batches: 2\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 2\n",
        "# warmup_steps: 8000\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 6\n",
        "dec_layers: 6\n",
        "heads: 8\n",
        "hidden_size: 512\n",
        "word_vec_size: 512\n",
        "transformer_ff: 2048\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "'''\n",
        "\n",
        "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(config)"
      ],
      "metadata": {
        "id": "lZ69S-sHaDfy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nproc --all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vDUluygfFYy",
        "outputId": "6d486213-1fa9-476a-a2ea-d4c827b54c24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# match -num_threads to number of CPUs to increase speed\n",
        "# -1 for -n_sample to use entire corpus when building vocab\n",
        "!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2"
      ],
      "metadata": {
        "id": "SH_-SZuTfI0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e91fea-9cfa-41d7-d285-2a0e146d0604"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-24 00:20:11.220270: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-24 00:20:11.220332: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-24 00:20:11.222161: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-24 00:20:11.232645: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-24 00:20:12.871031: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-01-24 00:20:14.190960: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-24 00:20:14.191391: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-24 00:20:14.191600: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2024-01-24 00:20:15,238 INFO] Counter vocab from -1 samples.\n",
            "[2024-01-24 00:20:15,238 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2024-01-24 00:20:44,730 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=839)\n",
            "\n",
            "[2024-01-24 00:20:44,879 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=785)\n",
            "\n",
            "[2024-01-24 00:20:45,013 INFO] Counters src: 49571\n",
            "[2024-01-24 00:20:45,013 INFO] Counters tgt: 49999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# once runtime type is changed to GPU, check that the GPU is active\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do2zzPXFfdeZ",
        "outputId": "806ae68b-222b-45e7-b18f-b262c003fb00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-495950c7-d9bc-9d3d-dd36-adffe3439b91)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check that the GPU is visible to PyTorch\n",
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "gpu_memory = torch.cuda.mem_get_info(0)\n",
        "print(\"Free GPU memory:\", gpu_memory[0] / 1024**2, \"out of\", gpu_memory[1] / 1024**2)"
      ],
      "metadata": {
        "id": "8Tz1-U5zgENR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee7e147-fa56-4b49-9221-d3d43c90fe74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n",
            "Free GPU memory: 14999.0625 out of 15102.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear the models directory for a fresh start\n",
        "!rm -rf /content/drive/MyDrive/nmt-tools/models"
      ],
      "metadata": {
        "id": "PO3lc2tdgMk4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train NMT model\n",
        "!onmt_train -config config.yaml"
      ],
      "metadata": {
        "id": "t8CZzr2XgS24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588c6048-6e75-4e29-a4fc-7a0a6fd50ba9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-24 00:20:52.369413: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-24 00:20:52.369470: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-24 00:20:52.371983: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-24 00:20:52.382420: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-24 00:20:53.947009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-01-24 00:20:54.978334: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-24 00:20:54.978762: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-24 00:20:54.978927: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2024-01-24 00:20:55,670 INFO] Parsed 2 corpora from -data.\n",
            "[2024-01-24 00:20:55,672 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2024-01-24 00:20:55,881 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '▁the', '▁of', ',', '.', '▁and', '▁to']\n",
            "[2024-01-24 00:20:55,881 INFO] The decoder start token is: <s>\n",
            "[2024-01-24 00:20:55,882 INFO] Building model...\n",
            "[2024-01-24 00:20:57,433 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2024-01-24 00:20:57,434 INFO] Non quantized layer compute is fp16\n",
            "[2024-01-24 00:20:57,798 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(49576, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-5): 6 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(50000, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=512, out_features=50000, bias=True)\n",
            ")\n",
            "[2024-01-24 00:20:57,801 INFO] encoder: 44270592\n",
            "[2024-01-24 00:20:57,801 INFO] decoder: 76435280\n",
            "[2024-01-24 00:20:57,801 INFO] * number of parameters: 120705872\n",
            "[2024-01-24 00:20:57,802 INFO] Trainable parameters = {'torch.float32': 120705872, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2024-01-24 00:20:57,802 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2024-01-24 00:20:57,802 INFO]  * src vocab size = 49576\n",
            "[2024-01-24 00:20:57,802 INFO]  * tgt vocab size = 50000\n",
            "[2024-01-24 00:20:58,386 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2024-01-24 00:20:58,387 INFO] Starting training on GPU: [0]\n",
            "[2024-01-24 00:20:58,387 INFO] Start training loop and validate every 2000 steps...\n",
            "[2024-01-24 00:20:58,387 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n",
            "[2024-01-24 00:23:59,844 INFO] Step 200/10000; acc: 7.1; ppl: 4575.9; xent: 8.4; lr: 0.00020; sents:   70622; bsz: 3110/3814/88; 13712/16814 tok/s;    181 sec;\n",
            "[2024-01-24 00:26:34,490 INFO] Step 400/10000; acc: 21.2; ppl: 316.7; xent: 5.8; lr: 0.00040; sents:   75784; bsz: 3132/3824/95; 16203/19781 tok/s;    336 sec;\n",
            "[2024-01-24 00:29:09,414 INFO] Step 600/10000; acc: 29.1; ppl: 150.9; xent: 5.0; lr: 0.00059; sents:   72777; bsz: 3076/3811/91; 15885/19681 tok/s;    491 sec;\n",
            "[2024-01-24 00:30:46,026 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=995)\n",
            "\n",
            "[2024-01-24 00:30:46,027 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2024-01-24 00:32:29,641 INFO] Step 800/10000; acc: 38.6; ppl:  83.5; xent: 4.4; lr: 0.00079; sents:   75764; bsz: 3093/3804/95; 12358/15197 tok/s;    691 sec;\n",
            "[2024-01-24 00:35:05,871 INFO] Step 1000/10000; acc: 46.6; ppl:  53.3; xent: 4.0; lr: 0.00099; sents:   71723; bsz: 3132/3828/90; 16038/19603 tok/s;    847 sec;\n",
            "[2024-01-24 00:37:41,708 INFO] Step 1200/10000; acc: 53.1; ppl:  38.0; xent: 3.6; lr: 0.00119; sents:   75651; bsz: 3115/3798/95; 15990/19498 tok/s;   1003 sec;\n",
            "[2024-01-24 00:40:17,654 INFO] Step 1400/10000; acc: 57.2; ppl:  30.5; xent: 3.4; lr: 0.00138; sents:   73073; bsz: 3092/3840/91; 15860/19700 tok/s;   1159 sec;\n",
            "[2024-01-24 00:43:37,622 INFO] Step 1600/10000; acc: 60.2; ppl:  25.8; xent: 3.2; lr: 0.00158; sents:   73824; bsz: 3105/3822/92; 12423/15290 tok/s;   1359 sec;\n",
            "[2024-01-24 00:46:13,266 INFO] Step 1800/10000; acc: 61.5; ppl:  24.0; xent: 3.2; lr: 0.00178; sents:   72547; bsz: 3100/3806/91; 15935/19564 tok/s;   1515 sec;\n",
            "[2024-01-24 00:48:49,109 INFO] Step 2000/10000; acc: 63.0; ppl:  22.2; xent: 3.1; lr: 0.00198; sents:   72874; bsz: 3110/3828/91; 15964/19653 tok/s;   1671 sec;\n",
            "[2024-01-24 00:48:53,489 INFO] valid stats calculation\n",
            "                           took: 4.37697434425354 s.\n",
            "[2024-01-24 00:48:53,490 INFO] Train perplexity: 82.9181\n",
            "[2024-01-24 00:48:53,490 INFO] Train accuracy: 43.7635\n",
            "[2024-01-24 00:48:53,490 INFO] Sentences processed: 734639\n",
            "[2024-01-24 00:48:53,490 INFO] Average bsz: 3107/3818/92\n",
            "[2024-01-24 00:48:53,490 INFO] Validation perplexity: 20.3221\n",
            "[2024-01-24 00:48:53,490 INFO] Validation accuracy: 64.7767\n",
            "[2024-01-24 00:48:53,491 INFO] Model is improving ppl: inf --> 20.3221.\n",
            "[2024-01-24 00:48:53,491 INFO] Model is improving acc: -inf --> 64.7767.\n",
            "[2024-01-24 00:48:53,508 INFO] Saving checkpoint models/model-base.enfr_step_2000.pt\n",
            "[2024-01-24 00:50:43,533 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=2033)\n",
            "\n",
            "[2024-01-24 00:50:43,533 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2024-01-24 00:52:21,145 INFO] Step 2200/10000; acc: 64.1; ppl:  20.7; xent: 3.0; lr: 0.00188; sents:   73551; bsz: 3113/3794/92; 11745/14313 tok/s;   1883 sec;\n",
            "[2024-01-24 00:54:57,185 INFO] Step 2400/10000; acc: 65.9; ppl:  18.7; xent: 2.9; lr: 0.00180; sents:   74037; bsz: 3107/3798/93; 15929/19470 tok/s;   2039 sec;\n",
            "[2024-01-24 00:57:33,781 INFO] Step 2600/10000; acc: 67.0; ppl:  17.6; xent: 2.9; lr: 0.00173; sents:   75129; bsz: 3117/3828/94; 15926/19556 tok/s;   2195 sec;\n",
            "[2024-01-24 01:00:10,238 INFO] Step 2800/10000; acc: 67.6; ppl:  16.9; xent: 2.8; lr: 0.00167; sents:   73292; bsz: 3106/3830/92; 15884/19582 tok/s;   2352 sec;\n",
            "[2024-01-24 01:00:53,309 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=990)\n",
            "\n",
            "[2024-01-24 01:00:53,309 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2024-01-24 01:03:28,945 INFO] Step 3000/10000; acc: 69.0; ppl:  15.5; xent: 2.7; lr: 0.00161; sents:   71334; bsz: 3109/3823/89; 12517/15390 tok/s;   2551 sec;\n",
            "[2024-01-24 01:06:04,806 INFO] Step 3200/10000; acc: 69.6; ppl:  15.0; xent: 2.7; lr: 0.00156; sents:   73478; bsz: 3106/3824/92; 15943/19628 tok/s;   2706 sec;\n",
            "[2024-01-24 01:08:40,662 INFO] Step 3400/10000; acc: 69.8; ppl:  14.9; xent: 2.7; lr: 0.00152; sents:   75563; bsz: 3097/3805/94; 15898/19530 tok/s;   2862 sec;\n",
            "[2024-01-24 01:12:02,548 INFO] Step 3600/10000; acc: 70.7; ppl:  14.1; xent: 2.6; lr: 0.00147; sents:   71043; bsz: 3118/3831/89; 12356/15182 tok/s;   3064 sec;\n",
            "[2024-01-24 01:14:38,421 INFO] Step 3800/10000; acc: 71.6; ppl:  13.3; xent: 2.6; lr: 0.00143; sents:   75985; bsz: 3108/3841/95; 15953/19715 tok/s;   3220 sec;\n",
            "[2024-01-24 01:17:13,920 INFO] Step 4000/10000; acc: 71.5; ppl:  13.4; xent: 2.6; lr: 0.00140; sents:   70686; bsz: 3098/3810/88; 15938/19601 tok/s;   3376 sec;\n",
            "[2024-01-24 01:17:14,086 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=11)\n",
            "\n",
            "[2024-01-24 01:17:17,354 INFO] valid stats calculation\n",
            "                           took: 3.432727575302124 s.\n",
            "[2024-01-24 01:17:17,356 INFO] Train perplexity: 36.2422\n",
            "[2024-01-24 01:17:17,356 INFO] Train accuracy: 56.2234\n",
            "[2024-01-24 01:17:17,356 INFO] Sentences processed: 1.46874e+06\n",
            "[2024-01-24 01:17:17,356 INFO] Average bsz: 3107/3818/92\n",
            "[2024-01-24 01:17:17,356 INFO] Validation perplexity: 13.7608\n",
            "[2024-01-24 01:17:17,356 INFO] Validation accuracy: 71.7919\n",
            "[2024-01-24 01:17:17,356 INFO] Model is improving ppl: 20.3221 --> 13.7608.\n",
            "[2024-01-24 01:17:17,356 INFO] Model is improving acc: 64.7767 --> 71.7919.\n",
            "[2024-01-24 01:17:17,372 INFO] Saving checkpoint models/model-base.enfr_step_4000.pt\n",
            "[2024-01-24 01:20:12,043 INFO] Step 4200/10000; acc: 71.7; ppl:  13.3; xent: 2.6; lr: 0.00136; sents:   73979; bsz: 3126/3815/92; 14040/17134 tok/s;   3554 sec;\n",
            "[2024-01-24 01:21:04,200 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=2022)\n",
            "\n",
            "[2024-01-24 01:21:04,200 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2024-01-24 01:23:38,306 INFO] Step 4400/10000; acc: 72.6; ppl:  12.6; xent: 2.5; lr: 0.00133; sents:   76180; bsz: 3083/3801/95; 11958/14742 tok/s;   3760 sec;\n",
            "[2024-01-24 01:26:14,385 INFO] Step 4600/10000; acc: 72.9; ppl:  12.4; xent: 2.5; lr: 0.00130; sents:   73748; bsz: 3094/3800/92; 15857/19476 tok/s;   3916 sec;\n",
            "[2024-01-24 01:28:50,253 INFO] Step 4800/10000; acc: 73.0; ppl:  12.3; xent: 2.5; lr: 0.00128; sents:   73055; bsz: 3104/3823/91; 15932/19624 tok/s;   4072 sec;\n",
            "[2024-01-24 01:32:11,202 INFO] Step 5000/10000; acc: 73.5; ppl:  12.0; xent: 2.5; lr: 0.00125; sents:   73854; bsz: 3150/3834/92; 12540/15264 tok/s;   4273 sec;\n",
            "[2024-01-24 01:34:47,237 INFO] Step 5200/10000; acc: 74.2; ppl:  11.5; xent: 2.4; lr: 0.00123; sents:   73108; bsz: 3111/3813/91; 15949/19552 tok/s;   4429 sec;\n",
            "[2024-01-24 01:37:23,180 INFO] Step 5400/10000; acc: 74.1; ppl:  11.6; xent: 2.4; lr: 0.00120; sents:   73962; bsz: 3084/3819/92; 15823/19594 tok/s;   4585 sec;\n",
            "[2024-01-24 01:39:59,343 INFO] Step 5600/10000; acc: 74.2; ppl:  11.6; xent: 2.5; lr: 0.00118; sents:   72699; bsz: 3111/3799/91; 15935/19461 tok/s;   4741 sec;\n",
            "[2024-01-24 01:40:56,982 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=1993)\n",
            "\n",
            "[2024-01-24 01:40:56,982 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2024-01-24 01:43:21,419 INFO] Step 5800/10000; acc: 74.9; ppl:  11.1; xent: 2.4; lr: 0.00116; sents:   74435; bsz: 3118/3826/93; 12343/15146 tok/s;   4943 sec;\n",
            "[2024-01-24 01:45:57,292 INFO] Step 6000/10000; acc: 75.1; ppl:  11.0; xent: 2.4; lr: 0.00114; sents:   74061; bsz: 3098/3799/93; 15901/19499 tok/s;   5099 sec;\n",
            "[2024-01-24 01:45:57,464 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=11)\n",
            "\n",
            "[2024-01-24 01:46:00,809 INFO] valid stats calculation\n",
            "                           took: 3.514622449874878 s.\n",
            "[2024-01-24 01:46:00,811 INFO] Train perplexity: 25.0245\n",
            "[2024-01-24 01:46:00,811 INFO] Train accuracy: 62.0175\n",
            "[2024-01-24 01:46:00,811 INFO] Sentences processed: 2.20782e+06\n",
            "[2024-01-24 01:46:00,811 INFO] Average bsz: 3107/3816/92\n",
            "[2024-01-24 01:46:00,811 INFO] Validation perplexity: 12.5118\n",
            "[2024-01-24 01:46:00,811 INFO] Validation accuracy: 73.7235\n",
            "[2024-01-24 01:46:00,812 INFO] Model is improving ppl: 13.7608 --> 12.5118.\n",
            "[2024-01-24 01:46:00,812 INFO] Model is improving acc: 71.7919 --> 73.7235.\n",
            "[2024-01-24 01:46:00,837 INFO] Saving checkpoint models/model-base.enfr_step_6000.pt\n",
            "[2024-01-24 01:49:04,328 INFO] Step 6200/10000; acc: 74.9; ppl:  11.1; xent: 2.4; lr: 0.00112; sents:   72425; bsz: 3099/3834/91; 13254/16400 tok/s;   5286 sec;\n",
            "[2024-01-24 01:51:35,883 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=989)\n",
            "\n",
            "[2024-01-24 01:51:35,883 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2024-01-24 01:52:25,445 INFO] Step 6400/10000; acc: 75.2; ppl:  10.9; xent: 2.4; lr: 0.00110; sents:   73031; bsz: 3117/3818/91; 12400/15187 tok/s;   5487 sec;\n",
            "[2024-01-24 01:54:58,080 INFO] Step 6600/10000; acc: 76.2; ppl:  10.3; xent: 2.3; lr: 0.00109; sents:   71998; bsz: 3101/3828/90; 16254/20063 tok/s;   5640 sec;\n",
            "[2024-01-24 01:57:32,795 INFO] Step 6800/10000; acc: 75.9; ppl:  10.5; xent: 2.4; lr: 0.00107; sents:   74558; bsz: 3119/3808/93; 16130/19690 tok/s;   5794 sec;\n",
            "[2024-01-24 02:00:07,330 INFO] Step 7000/10000; acc: 75.9; ppl:  10.5; xent: 2.4; lr: 0.00106; sents:   71911; bsz: 3100/3810/90; 16050/19724 tok/s;   5949 sec;\n",
            "[2024-01-24 02:03:25,686 INFO] Step 7200/10000; acc: 76.4; ppl:  10.3; xent: 2.3; lr: 0.00104; sents:   76625; bsz: 3120/3817/96; 12585/15396 tok/s;   6147 sec;\n",
            "[2024-01-24 02:05:58,515 INFO] Step 7400/10000; acc: 76.7; ppl:  10.1; xent: 2.3; lr: 0.00103; sents:   74722; bsz: 3084/3810/93; 16142/19944 tok/s;   6300 sec;\n",
            "[2024-01-24 02:08:32,647 INFO] Step 7600/10000; acc: 76.6; ppl:  10.1; xent: 2.3; lr: 0.00101; sents:   72261; bsz: 3116/3831/90; 16176/19883 tok/s;   6454 sec;\n",
            "[2024-01-24 02:11:11,431 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=2036)\n",
            "\n",
            "[2024-01-24 02:11:11,431 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2024-01-24 02:11:45,853 INFO] Step 7800/10000; acc: 76.5; ppl:  10.2; xent: 2.3; lr: 0.00100; sents:   72762; bsz: 3112/3814/91; 12885/15793 tok/s;   6647 sec;\n",
            "[2024-01-24 02:14:18,341 INFO] Step 8000/10000; acc: 77.8; ppl:   9.6; xent: 2.3; lr: 0.00099; sents:   76993; bsz: 3132/3828/96; 16434/20085 tok/s;   6800 sec;\n",
            "[2024-01-24 02:14:18,506 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=11)\n",
            "\n",
            "[2024-01-24 02:14:25,750 INFO] valid stats calculation\n",
            "                           took: 7.407334804534912 s.\n",
            "[2024-01-24 02:14:25,752 INFO] Train perplexity: 20.0696\n",
            "[2024-01-24 02:14:25,752 INFO] Train accuracy: 65.5706\n",
            "[2024-01-24 02:14:25,752 INFO] Sentences processed: 2.9451e+06\n",
            "[2024-01-24 02:14:25,752 INFO] Average bsz: 3108/3817/92\n",
            "[2024-01-24 02:14:25,752 INFO] Validation perplexity: 12.0232\n",
            "[2024-01-24 02:14:25,752 INFO] Validation accuracy: 74.6048\n",
            "[2024-01-24 02:14:25,752 INFO] Model is improving ppl: 12.5118 --> 12.0232.\n",
            "[2024-01-24 02:14:25,752 INFO] Model is improving acc: 73.7235 --> 74.6048.\n",
            "[2024-01-24 02:14:25,768 INFO] Saving checkpoint models/model-base.enfr_step_8000.pt\n",
            "[2024-01-24 02:17:20,788 INFO] Step 8200/10000; acc: 77.4; ppl:   9.8; xent: 2.3; lr: 0.00098; sents:   73123; bsz: 3090/3813/91; 13548/16720 tok/s;   6982 sec;\n",
            "[2024-01-24 02:19:54,950 INFO] Step 8400/10000; acc: 77.1; ppl:   9.9; xent: 2.3; lr: 0.00096; sents:   70626; bsz: 3095/3811/88; 16063/19779 tok/s;   7137 sec;\n",
            "[2024-01-24 02:21:37,288 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=983)\n",
            "\n",
            "[2024-01-24 02:21:37,289 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2024-01-24 02:23:14,306 INFO] Step 8600/10000; acc: 77.7; ppl:   9.6; xent: 2.3; lr: 0.00095; sents:   73055; bsz: 3125/3819/91; 12542/15324 tok/s;   7336 sec;\n",
            "[2024-01-24 02:25:47,410 INFO] Step 8800/10000; acc: 78.2; ppl:   9.4; xent: 2.2; lr: 0.00094; sents:   74370; bsz: 3103/3815/93; 16213/19935 tok/s;   7489 sec;\n",
            "[2024-01-24 02:28:21,877 INFO] Step 9000/10000; acc: 78.0; ppl:   9.5; xent: 2.3; lr: 0.00093; sents:   74539; bsz: 3102/3810/93; 16068/19731 tok/s;   7643 sec;\n",
            "[2024-01-24 02:30:56,623 INFO] Step 9200/10000; acc: 77.6; ppl:   9.6; xent: 2.3; lr: 0.00092; sents:   72176; bsz: 3106/3819/90; 16055/19746 tok/s;   7798 sec;\n",
            "[2024-01-24 02:34:15,226 INFO] Step 9400/10000; acc: 78.8; ppl:   9.1; xent: 2.2; lr: 0.00091; sents:   72498; bsz: 3128/3817/91; 12599/15377 tok/s;   7997 sec;\n",
            "[2024-01-24 02:36:49,141 INFO] Step 9600/10000; acc: 78.3; ppl:   9.3; xent: 2.2; lr: 0.00090; sents:   72926; bsz: 3088/3821/91; 16049/19861 tok/s;   8151 sec;\n",
            "[2024-01-24 02:39:24,071 INFO] Step 9800/10000; acc: 78.5; ppl:   9.2; xent: 2.2; lr: 0.00089; sents:   74752; bsz: 3112/3829/93; 16067/19773 tok/s;   8306 sec;\n",
            "[2024-01-24 02:41:13,214 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=2004)\n",
            "\n",
            "[2024-01-24 02:41:13,215 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2024-01-24 02:42:41,989 INFO] Step 10000/10000; acc: 78.8; ppl:   9.1; xent: 2.2; lr: 0.00088; sents:   74013; bsz: 3120/3829/93; 12611/15476 tok/s;   8504 sec;\n",
            "[2024-01-24 02:42:42,158 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=11)\n",
            "\n",
            "[2024-01-24 02:42:45,395 INFO] valid stats calculation\n",
            "                           took: 3.4037258625030518 s.\n",
            "[2024-01-24 02:42:45,397 INFO] Train perplexity: 17.2653\n",
            "[2024-01-24 02:42:45,397 INFO] Train accuracy: 68.0642\n",
            "[2024-01-24 02:42:45,397 INFO] Sentences processed: 3.67718e+06\n",
            "[2024-01-24 02:42:45,397 INFO] Average bsz: 3108/3817/92\n",
            "[2024-01-24 02:42:45,397 INFO] Validation perplexity: 11.937\n",
            "[2024-01-24 02:42:45,397 INFO] Validation accuracy: 74.971\n",
            "[2024-01-24 02:42:45,397 INFO] Model is improving ppl: 12.0232 --> 11.937.\n",
            "[2024-01-24 02:42:45,397 INFO] Model is improving acc: 74.6048 --> 74.971.\n",
            "[2024-01-24 02:42:45,413 INFO] Saving checkpoint models/model-base.enfr_step_10000.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in case Colab is suddenly unable to navigate through directories\n",
        "import os\n",
        "path = '/content/drive/MyDrive/domain-adapted-nmt/nmt-tools'\n",
        "os.chdir(path)"
      ],
      "metadata": {
        "id": "qeAMnd2X2uuA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -gpu 0 to use gpu\n",
        "!onmt_translate -model models/model-base.enfr_step_10000.pt -src corpora/enfr/en-fr-general.en-filtered.en.subword.test -output general-fr.translated -gpu 0 -min_length 1"
      ],
      "metadata": {
        "id": "cdKHqwOJ1kKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba269d97-f70d-430d-bf32-3f60f99f6eef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-24 02:44:04.733112: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-24 02:44:04.733175: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-24 02:44:04.735231: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-24 02:44:04.767921: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-24 02:44:06.891483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-01-24 02:44:08.600018: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-24 02:44:08.600428: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-24 02:44:08.600644: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2024-01-24 02:44:09,016 INFO] Loading checkpoint from models/model-base.enfr_step_10000.pt\n",
            "[2024-01-24 02:44:12,028 INFO] Loading data into the model\n",
            "[2024-01-24 02:45:42,796 INFO] PRED SCORE: -0.3127, PRED PPL: 1.37 NB SENTENCES: 3000\n",
            "Time w/o python interpreter load/terminate:  93.84438824653625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 5 general-fr.translated"
      ],
      "metadata": {
        "id": "FVwRgj_O1nXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ebbb61-c730-4293-e8a0-0755b5bfc72d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁Il ▁ne ▁faut ▁pas ▁oublier ▁que ▁ 1 ▁ 2 6 0 ▁prisonniers ▁marocains ▁sont ▁toujours ▁détenus ▁dans ▁des ▁prisons ▁du ▁Front ▁POLISARIO , ▁où ▁ils ▁ont ▁été ▁maintenus ▁pendant ▁plus ▁de ▁ 2 5 ▁ans ▁en ▁violation ▁flagrante ▁du ▁droit ▁international ▁humanitaire .\n",
            "▁Fournir ▁au ▁Comité ▁des ▁exemplaires ▁du ▁texte ▁de ▁la ▁Convention ▁relative ▁aux ▁droits ▁de ▁l ' enfant ▁dans ▁toutes ▁les ▁langues ▁officielles ▁ou ▁dans ▁d ' autres ▁langues ▁ou ▁dialectes , ▁lorsque ▁cela ▁est ▁disponible .\n",
            "▁Nous ▁réaffirmons ▁que ▁les ▁lois ▁en ▁vigueur ▁dans ▁le ▁Sultanat ▁garantissent ▁la ▁protection ▁des ▁droits ▁de ▁l ' homme , ▁y ▁compris ▁les ▁droits ▁de ▁l ' enfant , ▁en ▁particulier ▁en ▁ce ▁qui ▁concerne ▁l ' implication ▁d ' enfants ▁dans ▁les ▁conflits ▁armés .\n",
            "▁Conformément ▁à ▁l ' accord ▁auquel ▁le ▁Conseil ▁est ▁parvenu ▁lors ▁de ▁ses ▁consultations ▁préalables , ▁j ' invite ▁les ▁membres ▁du ▁Conseil ▁à ▁poursuivre ▁l ' examen ▁de ▁la ▁question .\n",
            "▁Décisions ▁et ▁recommandations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade -q sentencepiece"
      ],
      "metadata": {
        "id": "f76FH1TE1quR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4576099-cfd3-45fe-8a14-82caebbf4422"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# desubword translated file\n",
        "!python3 MT-Preparation/subwording/3-desubword.py target-general.model general-fr.translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0e2k30QWshy",
        "outputId": "dd576ffb-19b0-40c2-b1d6-8b482844c005"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: general-fr.translated.desubword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 5 general-fr.translated.desubword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXEr-jHqWqXN",
        "outputId": "ac1c66be-7c53-427e-9405-fcfdafab281a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il ne faut pas oublier que 1 260 prisonniers marocains sont toujours détenus dans des prisons du Front POLISARIO, où ils ont été maintenus pendant plus de 25 ans en violation flagrante du droit international humanitaire.\n",
            "Fournir au Comité des exemplaires du texte de la Convention relative aux droits de l'enfant dans toutes les langues officielles ou dans d'autres langues ou dialectes, lorsque cela est disponible.\n",
            "Nous réaffirmons que les lois en vigueur dans le Sultanat garantissent la protection des droits de l'homme, y compris les droits de l'enfant, en particulier en ce qui concerne l'implication d'enfants dans les conflits armés.\n",
            "Conformément à l'accord auquel le Conseil est parvenu lors de ses consultations préalables, j'invite les membres du Conseil à poursuivre l'examen de la question.\n",
            "Décisions et recommandations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 MT-Preparation/subwording/3-desubword.py target-general.model corpora/enfr/en-fr-general.fr-filtered.fr.subword.test"
      ],
      "metadata": {
        "id": "E_1RhBhL1tZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2167c3df-9e7c-46a2-a775-9697e1488929"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: corpora/enfr/en-fr-general.fr-filtered.fr.subword.test.desubword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 5 corpora/enfr/en-fr-general.fr-filtered.fr.subword.test.desubword"
      ],
      "metadata": {
        "id": "ZG3qa1AX_o9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc1c5268-f355-4fea-a113-2e66c078cfe3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il ne faut pas oublier que 1 260 détenus marocains sont toujours en captivité dans les geôles du Polisario, et ce depuis plus de 25 ans, en violation flagrante du droit international humanitaire.\n",
            "Faire parvenir au Comité des exemplaires du texte de la Convention relative aux droits de l'enfant dans toutes les langues officielles de l'État partie ainsi que dans ses autres langues ou dialectes, si elle a été traduite.\n",
            "Nous réaffirmons que la législation en vigueur dans le Sultanat garantit la protection des droits de l'homme, y compris les droits de l'enfant, en particulier pour ce qui est de l'implication d'enfants dans les conflits armés.\n",
            "Conformément à l'accord auquel le Conseil est parvenu lors de ses consultations préalables, j'invite à présent les membres du Conseil à poursuivre le débat sur la question dans le cadre de consultations.\n",
            "Décisions et recommandations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test bleu for baseline score\n",
        "!wget https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n",
        "!pip3 install sacrebleu"
      ],
      "metadata": {
        "id": "T5bw8Qqp1uzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ee8f69-1686-4430-f5cd-cbe139ebce4d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-24 02:43:49--  https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 957 [text/plain]\n",
            "Saving to: ‘compute-bleu.py’\n",
            "\n",
            "compute-bleu.py     100%[===================>]     957  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-24 02:43:49 (4.60 MB/s) - ‘compute-bleu.py’ saved [957/957]\n",
            "\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 compute-bleu.py corpora/enfr/en-fr-general.fr-filtered.fr.subword.test.desubword general-fr.translated.desubword\n",
        "# !python3 compute-bleu.py corpora/enfr/en-fr-general.en-filtered.en.subword.test.desubword general-fr.translated.desubword"
      ],
      "metadata": {
        "id": "ZidBkQGF5xAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b0ae7a-805c-46f9-ed34-252d32aa7fe0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference 1st sentence: Il ne faut pas oublier que 1 260 détenus marocains sont toujours en captivité dans les geôles du Polisario, et ce depuis plus de 25 ans, en violation flagrante du droit international humanitaire.\n",
            "MTed 1st sentence: Il ne faut pas oublier que 1 260 prisonniers marocains sont toujours détenus dans des prisons du Front POLISARIO, où ils ont été maintenus pendant plus de 25 ans en violation flagrante du droit international humanitaire.\n",
            "BLEU:  43.0993809551098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tech = \"\"\"# tech.yaml\n",
        "# for technology corpus/model fine-tuning\n",
        "share_vocab: true\n",
        "src_vocab:\n",
        "tgt_vocab:\n",
        "data:\n",
        "  # different corpus weighting for mixed fine-tuning approach\n",
        "  tech_corpus:\n",
        "    path_src:\n",
        "    path_tgt:\n",
        "    transforms:\n",
        "    weight: 10\n",
        "  gen_corpus:\n",
        "    path_src:\n",
        "    path_tgt:\n",
        "    transforms:\n",
        "    weight: 1\n",
        "\n",
        "update_vocab: true\n",
        "train_from: '' # the base model trained earlier\n",
        "reset_optim: all\n",
        "\n",
        "save_data:\n",
        "save_model:\n",
        "log_file:\n",
        "\n",
        "keep_checkpoint: 50\n",
        "save_checkpoint_steps: 100\n",
        "average_decay: 0.0005\n",
        "seed: 1234\n",
        "report_every: 10\n",
        "\n",
        "train_steps:\n",
        "valid_steps:\n",
        "\n",
        "# batching\n",
        "bucket_size: 262144\n",
        "num_workers: 0\n",
        "\"\"\"\n",
        "\n",
        "with open(\"tech.yaml\", \"w+\") as tech_yaml:\n",
        "  tech_yaml.write(tech)"
      ],
      "metadata": {
        "id": "05xpXlOBwjAJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}